# YAML file for Paperspace Gradient NLP Text Generation Tutorial example
# It runs the GPT-2 model from HuggingFace: https://huggingface.co/gpt2
#
# The Workflow is triggered when this is present in the .gradient/workflows/ directory in a GitHub
# repository linked to the user's Gradient project
# It clones this repo and then in turn calls the file nlp_text_generation.py
# This file outputs the generated text to outputs.txt in a Gradient-managed Dataset
# Updated to use modern Python 3.10+ image with GPU support and CUDA-matched PyTorch
#
# See the Gradient documentation page for more details:
# https://docs.paperspace.com/gradient/get-started/tutorials-list/example-workflow-nlp-text-generator
#
# Last updated: August 2025
on:
  github:
    branches:
      only: main
jobs:
  cloneRepo:
    resources:
      instance-type: P4000
    outputs:
      repo:
        type: volume
    uses: git-checkout@v1
    with:
      url: context.event.github.url
      ref: context.event.github.ref
  generateText:
    resources:
      instance-type: P4000
    needs:
      - cloneRepo
    inputs:
      repo: cloneRepo.outputs.repo
    outputs:
      generatedText:
        type: dataset
        with:
          ref: demo-dataset
    uses: script@v1
    with:
      script: |-
        cp -R /inputs/repo /nlp
        cd /nlp
        # Install CUDA-matched PyTorch and transformers
        python3 -m pip install --upgrade pip
        python3 -m pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118
        python3 -m pip install transformers>=4.30.0 datasets accelerate
        # Verify CUDA is available
        python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
        python3 nlp_text_generation.py
        mv output.txt /outputs/generatedText
        ls "-aFlR" /outputs/generatedText
      image: nvidia/cuda:11.8-devel-ubuntu20.04
# Appendix: Extra details
#
# Updated to use modern CUDA 11.8 base image with Python 3.10+ support
# Added explicit CUDA-matched PyTorch installation for GPU acceleration
# The generateText job now uses P4000 GPU instance for better performance
# Added verification step to ensure CUDA is properly detected
# Updated transformers to version 4.30+ for better model support
